{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenet_start.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1esQQVikNcpGigtgmVF-QP6p47Ikra-23",
          "timestamp": 1531831731455
        },
        {
          "file_id": "/v2/external/notebooks/welcome.ipynb",
          "timestamp": 1529240593757
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9J7p406abzgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part IV:  [Mobilenet](https://arxiv.org/pdf/1704.04861.pdf) separable convolutions\n",
        "- modify the model in part I to use *separable* convolutions\n",
        "- check number of parameters and compare with the previous model\n",
        "- train classifier\n",
        "\n",
        "Architecture (same as in part I):\n",
        "- conv output channels 64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512\n",
        "- kernel shape (3,3)\n",
        "- strides: 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1\n",
        "- padding: SAME (snt.SAME)\n",
        "- num_output_classes = 10\n"
      ]
    },
    {
      "metadata": {
        "id": "FhWI4Pix5GJw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "na0VvPXmYKp1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f637296-2099-41d3-8e0d-be653f393f33",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531831775305,
          "user_tz": -60,
          "elapsed": 4502,
          "user": {
            "displayName": "Diana Borsa",
            "photoUrl": "//lh3.googleusercontent.com/-ncAFLYhkpa4/AAAAAAAAAAI/AAAAAAAABCo/oObvci_cgWA/s50-c-k-no/photo.jpg",
            "userId": "113702420363391077417"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Don't forget to select GPU runtime environment in Runtime -> Change runtime type\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# we will use Sonnet on top of TF \n",
        "!pip install -q dm-sonnet\n",
        "import sonnet as snt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Plotting library.\n",
        "from matplotlib import pyplot as plt\n",
        "import pylab as pl\n",
        "from IPython import display"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1xlKHOLbhvY7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Reset graph\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8g16XweXs2Uq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download dataset to be used for training and testing\n",
        "- Cifar-10 equivalent of MNIST for natural RGB images\n",
        "- 60000 32x32 colour images in 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
        "- train: 50000; test: 10000"
      ]
    },
    {
      "metadata": {
        "id": "1g_EOx07s1XZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "# (down)load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rt6hU4aQtwpZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "cellView": "form",
        "outputId": "5a799c79-1b62-48c9-e75e-286947ad0a94",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531831780156,
          "user_tz": -60,
          "elapsed": 844,
          "user": {
            "displayName": "Diana Borsa",
            "photoUrl": "//lh3.googleusercontent.com/-ncAFLYhkpa4/AAAAAAAAAAI/AAAAAAAABCo/oObvci_cgWA/s50-c-k-no/photo.jpg",
            "userId": "113702420363391077417"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title (optional) Check sizes of tensors\n",
        "print ('Size of training images')\n",
        "print (train_images.shape)\n",
        "print ('Size of training labels')\n",
        "print (train_labels.shape)\n",
        "print ('Size of test images')\n",
        "print (test_images.shape)\n",
        "print ('Size of test labels')\n",
        "print (test_labels.shape)\n",
        "\n",
        "assert train_images.shape[0] == train_labels.shape[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training images\n",
            "(50000, 32, 32, 3)\n",
            "Size of training labels\n",
            "(50000, 1)\n",
            "Size of test images\n",
            "(10000, 32, 32, 3)\n",
            "Size of test labels\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JHAggitWu94_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare the data for training and testing\n",
        "- for training, we use stochastic optimizers (e.g. SGD, Adam), so we need to sample at random mini-batches from the training dataset\n",
        "- for testing, we iterate sequentially through the test set"
      ]
    },
    {
      "metadata": {
        "id": "iZofMjOuUEOF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "# define dimension of the batches to sample from the datasets\n",
        "BATCH_SIZE_TRAIN = 128 #@param\n",
        "BATCH_SIZE_TEST = 100 #@param\n",
        "\n",
        "# create Dataset objects using the data previously downloaded\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "# we shuffle the data and sample repeatedly batches for training\n",
        "batched_dataset_train = dataset_train.shuffle(100000).repeat().batch(BATCH_SIZE_TRAIN)\n",
        "# create iterator to retrieve batches\n",
        "iterator_train = batched_dataset_train.make_one_shot_iterator()\n",
        "# get a training batch of images and labels\n",
        "(batch_train_images, batch_train_labels) = iterator_train.get_next()\n",
        "\n",
        "# check that the shape of the training batches is the expected one\n",
        "# print ('Shape of training images')\n",
        "# print (batch_train_images)\n",
        "# print ('Shape of training labels')\n",
        "# print (batch_train_labels)\n",
        "\n",
        "# we do the same for test dataset\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "batched_dataset_test = dataset_test.repeat().batch(BATCH_SIZE_TEST)\n",
        "iterator_test = batched_dataset_test.make_one_shot_iterator() \n",
        "(batch_test_images, batch_test_labels) = iterator_test.get_next()\n",
        "# print ('Shape of test images')\n",
        "# print (batch_test_images)\n",
        "# print ('Shape of test labels')\n",
        "# print (batch_test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_PS2GjTxRZx9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Preprocessing of data\n",
        "# preprocess input for training and testing\n",
        "def random_flip_left_right(image, flip_index, seed=None):\n",
        "  shape = image.get_shape()\n",
        "  if shape.ndims == 3 or shape.ndims is None:\n",
        "    uniform_random = tf.random_uniform([], 0, 1.0, seed=seed)\n",
        "    mirror_cond = tf.less(uniform_random, .5)\n",
        "    result = tf.cond(\n",
        "        mirror_cond,\n",
        "        lambda: tf.reverse(image, [flip_index]),\n",
        "        lambda: image\n",
        "    )\n",
        "    return fix_image_flip_shape(image, result)\n",
        "  elif shape.ndims == 4:\n",
        "    uniform_random = tf.random_uniform(\n",
        "        [tf.shape(image)[0]], 0, 1.0, seed=seed\n",
        "    )\n",
        "    mirror_cond = tf.less(uniform_random, .5)\n",
        "    return tf.where(\n",
        "        mirror_cond,\n",
        "        image,\n",
        "        tf.map_fn(lambda x: tf.reverse(x, [flip_index]), image, dtype=image.dtype)\n",
        "    )\n",
        "  else:\n",
        "    raise ValueError(\"\\'image\\' must have either 3 or 4 dimensions.\")\n",
        "    \n",
        "def train_image_preprocess(h, w, random_flip=True):\n",
        "  \"\"\"Image processing required for training the model.\"\"\"\n",
        "\n",
        "  def fn(image):\n",
        "    batch_size = image.get_shape().as_list()[0]\n",
        "    # Ensure the data is in range [-1, 1].\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    image = image * 2.0 - 1.0\n",
        "    # Randomly choose a (24, 24, 3) patch to be used for training.\n",
        "    image = tf.random_crop(image, size=(BATCH_SIZE_TRAIN, h, w, 3))\n",
        "    # Randomly flip the image.\n",
        "    image = random_flip_left_right(image, 2)\n",
        "    return image\n",
        "\n",
        "  return fn\n",
        "\n",
        "def test_image_preprocess():\n",
        "  def fn(image):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    image = image * 2.0 - 1.0\n",
        "    return image\n",
        "  return fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jnsUw-N6lMng",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Separable convolutions\n",
        "\n",
        "For example, a 2D conv can be written as a sequence of 2 1D conv, i.e. \\begin{equation} y[m,n]=x[m,n]*h[m,n] = h_1[m]*(h_2[n]*x[m,n])\\end{equation}\n",
        "\n",
        "assuming $x$ is a 2D input signal, $h$ is a 2D filter that can be separated into 2 1D filters $h_1$ and $h_2$, and $y$ is the output of convolving $x$ with $h$.  \n",
        "\n",
        "\n",
        "Similarly for 3D case, we apply the separability between feature channel and spatial dimensions (as shown in the figure below on the left), i.e. \\begin{equation} y[m,n,p]=x[m,n, p]*h[m,n,p] = h_1[p]*(h_2[m,n]*x[m,n,p])\\end{equation}\n",
        "\n",
        "![alt text](https://tmlss.ro/lab_tmp/separable.png)"
      ]
    },
    {
      "metadata": {
        "id": "oAn3iRDvlXEa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Modify the previous classifier to use *separable* convolutions; the first conv unit stays the same."
      ]
    },
    {
      "metadata": {
        "id": "YW52gs-gldhY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class Mobilenet(snt.AbstractModule):\n",
        "  \n",
        "  def __init__(self, num_classes, name=\"mobilenet\"):\n",
        "    super(Mobilenet, self).__init__(name=name)\n",
        "    self._num_classes = num_classes\n",
        "    self._channel_multipliers = [\n",
        "        0, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1\n",
        "    ]\n",
        "    self._output_channels = [\n",
        "        64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512\n",
        "    ]\n",
        "    self._num_layers = len(self._output_channels)\n",
        "\n",
        "    self._kernel_shapes = [[3, 3]] * self._num_layers  # All kernels are 3x3.\n",
        "    self._strides = [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1]\n",
        "    self._paddings = [snt.SAME] * self._num_layers\n",
        "   \n",
        "  def _build(self, inputs, is_training=None, test_local_stats=False):\n",
        "    net = inputs\n",
        "    # instantiate all the convolutional layers\n",
        "    \n",
        "    # instantiate depthwise conv layers\n",
        "    \n",
        "    # instantiate 1x1 conv layers\n",
        "    \n",
        "    # construct network    \n",
        "\n",
        "    net = tf.reduce_mean(net, reduction_indices=[1, 2], keepdims=False,\n",
        "                         name=\"avg_pool\")\n",
        "\n",
        "    logits = snt.Linear(self._num_classes)(net)\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z4F6qR1OT0oj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Parameter Comparison\n",
        "\n",
        "What are the number of the parameters of this new model. How does it compare with the number computed for the baseline?"
      ]
    },
    {
      "metadata": {
        "id": "OD8IR90m_0-r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title Function to compute nr of params\n",
        "\n",
        "def get_num_params(scope):\n",
        "  total_parameters = 0\n",
        "  for variable in tf.trainable_variables(scope):\n",
        "    # shape is an array of tf.Dimension\n",
        "    shape = variable.get_shape()\n",
        "    variable_parameters = 1\n",
        "    for dim in shape:\n",
        "      variable_parameters *= dim.value\n",
        "    total_parameters += variable_parameters\n",
        "  return total_parameters\n",
        "\n",
        "#get_num_params('mobilenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inX9OlHW5xWR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Connect the model to the data \n"
      ]
    },
    {
      "metadata": {
        "id": "TZzlpO0oJFZy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# First define the preprocessing ops for the train/test data\n",
        "crop_height = 24 #@param\n",
        "cropt_width = 24 #@param\n",
        "preprocess_fn_train = train_image_preprocess(crop_height, cropt_width)\n",
        "preprocess_fn_test = test_image_preprocess()\n",
        "\n",
        "num_classes = 10 #@param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5K4VMXej8Fem",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# for evaluation, we look at top_k_accuracy since it's easier to interpret; normally k=1 or k=5\n",
        "def top_k_accuracy(k, labels, logits):\n",
        "  in_top_k = tf.nn.in_top_k(predictions=tf.squeeze(logits), targets=tf.squeeze(tf.cast(labels, tf.int32)), k=k)\n",
        "  return tf.reduce_mean(tf.cast(in_top_k, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G_6cvqi_nuZ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Instantiate Mobilenet, get number of parameters and compare with baseline"
      ]
    },
    {
      "metadata": {
        "id": "a86sl1lLmOVc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8a0ae2e5-5b27-40b9-9866-a8e2834ff72e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531831795081,
          "user_tz": -60,
          "elapsed": 1926,
          "user": {
            "displayName": "Diana Borsa",
            "photoUrl": "//lh3.googleusercontent.com/-ncAFLYhkpa4/AAAAAAAAAAI/AAAAAAAABCo/oObvci_cgWA/s50-c-k-no/photo.jpg",
            "userId": "113702420363391077417"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(\"mobilenet_model\"):\n",
        "  mobilenet = Mobilenet(num_classes=10)\n",
        "\n",
        "predictions_mobilenet = mobilenet(preprocess_fn_train(batch_train_images), is_training=True)\n",
        "print (predictions_mobilenet)\n",
        "test_predictions_mobilenet = mobilenet(preprocess_fn_test(batch_test_images), is_training=False)\n",
        "print (test_predictions_mobilenet)\n",
        "  \n",
        "print ('Number of parameters of Mobilenet is')\n",
        "print (get_num_params(\"mobilenet_model\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"mobilenet/linear/add:0\", shape=(128, 10), dtype=float32)\n",
            "Tensor(\"mobilenet_1/linear/add:0\", shape=(?, 10), dtype=float32)\n",
            "Number of parameters of Mobilenet is\n",
            "1079050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lGyLJwJ408ZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create the optimizer: SGD with momentum"
      ]
    },
    {
      "metadata": {
        "id": "f8V7fy_U2yY2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_optimizer(step):\n",
        "  \"\"\"Get the optimizer used for training.\"\"\"\n",
        "  lr_schedule = (40e3, 60e3, 80e3)\n",
        "  lr_schedule = tf.to_int64(lr_schedule)\n",
        "  lr_factor = 0.1\n",
        "  \n",
        "  lr_init = 0.1\n",
        "  num_epochs = tf.reduce_sum(tf.to_float(step >= lr_schedule))\n",
        "  lr = lr_init * lr_factor**num_epochs\n",
        "\n",
        "  return tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eO1xIgRtjvXU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_IMAGES = 10\n",
        "def gallery(seq, lbl, class_dict, title='Display input'):\n",
        "  num_frames, h, w, num_channels = seq.shape\n",
        "  num_frames = min(num_frames, MAX_IMAGES)\n",
        "  ff, axes = plt.subplots(1, num_frames,\n",
        "                          figsize=(num_frames, 1),\n",
        "                          subplot_kw={'xticks': [], 'yticks': []})\n",
        "  for i in range(0, num_frames):\n",
        "    if num_channels == 3:\n",
        "      axes[i].imshow(np.squeeze(seq[i]))\n",
        "    else:\n",
        "      axes[i].imshow(np.squeeze(seq[i]), cmap='gray')\n",
        "    axes[i].set_title(class_dict[lbl[i][0]])\n",
        "    plt.setp(axes[i].get_xticklabels(), visible=False)\n",
        "    plt.setp(axes[i].get_yticklabels(), visible=False)\n",
        "  ff.subplots_adjust(wspace=0.1)\n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PTFLYiWv8Z_n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set up the training"
      ]
    },
    {
      "metadata": {
        "id": "s-m8-e5vpUIQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define number of training iterations and reporting intervals\n",
        "TRAIN_ITERS = 90e3 #@param\n",
        "REPORT_TRAIN_EVERY = 100 #@param\n",
        "PLOT_EVERY = 500 #@param\n",
        "REPORT_TEST_EVERY = 1000 #@param\n",
        "TEST_ITERS = 10 #@param\n",
        "lr_init = 0.1 #@param\n",
        "display_inputs = False #@param\n",
        "\n",
        "class_mapping = [u'airplane', u'automobile', u'bird', u'cat', u'deer', u'dog', u'frog', u'horse', u'ship', u'truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pF0oEXrHFB7W",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Write a function that takes a list of losses and plots them.\n",
        "def plot_losses(loss_list, steps):\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(pl.gcf())\n",
        "  pl.plot(steps, loss_list)\n",
        "  time.sleep(1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mKOKrcm07DWW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training MobileNet\n"
      ]
    },
    {
      "metadata": {
        "id": "7lTGliNcnIfE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define train and test loss functions\n",
        "\n",
        "# Create a global step that is incremented during training; useful for e.g. learning rate annealing\n",
        "global_step = tf.train.get_or_create_global_step()\n",
        "\n",
        "# instantiate the optimizer\n",
        "optimizer, lr_op = get_optimizer(global_step)\n",
        "\n",
        "# Get training and test ops\n",
        "# training_op = \n",
        "# update_ops = \n",
        "# training_op = tf.group(training_op, update_ops)\n",
        "\n",
        "test_acc_op = top_k_accuracy(1, batch_test_labels, test_predictions_mobilenet)\n",
        "\n",
        "# Create the session and initialize variables\n",
        "sess = tf.Session()\n",
        "sess.run(tf.initialize_all_variables())\n",
        "\n",
        "# run training; at every k iterations, run evaluation too\n",
        "train_iter = 0\n",
        "display_inputs = False\n",
        "losses = []\n",
        "steps = []\n",
        "for train_iter in range(int(TRAIN_ITERS)):\n",
        "  _, train_loss, lr, img_inp, lbl_inp = sess.run([training_op, train_loss_op, lr_op, batch_train_images, batch_train_labels])\n",
        "  \n",
        "  if (train_iter % REPORT_TRAIN_EVERY) == 0:\n",
        "    print ('Train loss at iter {0:5d} out of {1:5d} is {2:.2f}'.format(int(train_iter), int(TRAIN_ITERS), train_loss)) \n",
        "    \n",
        "  if (train_iter % REPORT_TEST_EVERY) == 0:\n",
        "    avg_acc = 0.0\n",
        "    for test_iter in range(TEST_ITERS):\n",
        "      acc = sess.run(test_acc_op)\n",
        "      avg_acc += acc\n",
        "      \n",
        "    if display_inputs:\n",
        "      gallery(img_inp, lbl_inp, class_mapping)\n",
        "    avg_acc /= (TEST_ITERS)\n",
        "    print ('Test acc at iter {0:5d} out of {1:5d} is {2:.2f}'.format(int(train_iter), int(TRAIN_ITERS), avg_acc*100.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9kwj9LLvSl6j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}