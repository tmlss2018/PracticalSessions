{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "distillation_start.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "/v2/external/notebooks/welcome.ipynb",
          "timestamp": 1529240593757
        }
      ],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lzkm9_53o1H4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part III: [Distilling the knowledge](https://arxiv.org/pdf/1503.02531.pdf) from a (larger) teacher model\n",
        "\n",
        "- import an already trained baseline model\n",
        "- add KL distillation loss between teacher and student\n",
        "- train Mobilenet classifier with this joint loss\n"
      ]
    },
    {
      "metadata": {
        "id": "W5f4X7Zbpat0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Mobilenet with distillation loss, we use Kullback-Leibler (KL) divergence \n",
        "\n",
        "Define loss as\n",
        "\\begin{equation}\n",
        "\\mathcal{L} = \\lambda \\mathcal{L}_{\\text{distill}} + \\mathcal{L}_{\\text{classif}}\n",
        "\\end{equation}\n",
        "\n",
        "where\n",
        "\\begin{equation}\n",
        "\\mathcal{L}_{\\text{distill}} = \\text{KL}(\\text{p}_{\\text{teacher}}, \\text{p}_{\\text{student}}).\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Recall the definition of\n",
        "$$\\text{KL}(p||q) = \\sum_{i=1}^{N}p(x_i) \\cdot \\log \\frac{p(x_i)}{q(x_i)} . $$\n",
        "\n",
        "The outputs of the networks are logits, which we interpret as probabilities when passed through softmax:\n",
        "\n",
        "$$p_i^{(T)} =\\frac{\\exp{(\\text{logits}_i / T) }}{\\sum_j \\exp{(\\text{logits}_j / T) }} $$\n",
        "\n",
        "where $T$ is a temperature and usually we set it to $1$. Setting it to a higher number smoothens the probability distribution. To be fully precise, we will use\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathcal{L}_{\\text{distill}} = \\text{KL}(\\text{p}_{\\text{teacher}}^{(T)}, \\text{p}_{\\text{student}}^{(T)}),\n",
        "\\end{equation}\n",
        "\n",
        "$$\\lambda = T^2.$$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FhWI4Pix5GJw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "na0VvPXmYKp1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc4e0be7-100f-4612-b13c-874f81ac01bf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531832055703,
          "user_tz": -60,
          "elapsed": 4871,
          "user": {
            "displayName": "Mihaela Rosca",
            "photoUrl": "//lh5.googleusercontent.com/-q8OFNZCyEkk/AAAAAAAAAAI/AAAAAAAABJg/Qg8HHX2XAI0/s50-c-k-no/photo.jpg",
            "userId": "107992561331291226743"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Don't forget to select GPU runtime environment in Runtime -> Change runtime type\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# we will use Sonnet on top of TF \n",
        "!pip install -q dm-sonnet\n",
        "import sonnet as snt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Plotting library.\n",
        "from matplotlib import pyplot as plt\n",
        "import pylab as pl\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1xlKHOLbhvY7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Reset graph\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V5JKC1HMpnmF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Copy the pretrained weights of baseline model on the virtual machine\n",
        "- you need to load all three files in the *baseline_weights* folder"
      ]
    },
    {
      "metadata": {
        "id": "cubpPmHgECbc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "48b08d02-ab51-4ef7-fa5d-e3da97df8e77"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4c1e7b6b-5293-4974-9ff3-141c883c3479\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4c1e7b6b-5293-4974-9ff3-141c883c3479\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving baseline.ckpt.data-00000-of-00001 to baseline.ckpt (1).data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8g16XweXs2Uq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download dataset to be used for training and testing\n",
        "- Cifar-10 equivalent of MNIST for natural RGB images\n",
        "- 60000 32x32 colour images in 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
        "- train: 50000; test: 10000"
      ]
    },
    {
      "metadata": {
        "id": "1g_EOx07s1XZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "# (down)load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JHAggitWu94_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare the data for training and testing\n",
        "- for training, we use stochastic optimizers (e.g. SGD, Adam), so we need to sample at random mini-batches from the training dataset\n",
        "- for testing, we iterate sequentially through the test set"
      ]
    },
    {
      "metadata": {
        "id": "iZofMjOuUEOF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define dimension of the batches to sample from the datasets\n",
        "BATCH_SIZE_TRAIN = 64 #@param\n",
        "BATCH_SIZE_TEST = 100 #@param\n",
        "\n",
        "# create Dataset objects using the data previously downloaded\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "# we shuffle the data and sample repeatedly batches for training\n",
        "batched_dataset_train = dataset_train.shuffle(100000).repeat().batch(BATCH_SIZE_TRAIN)\n",
        "# create iterator to retrieve batches\n",
        "iterator_train = batched_dataset_train.make_one_shot_iterator()\n",
        "# get a training batch of images and labels\n",
        "(batch_train_images, batch_train_labels) = iterator_train.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yWtdQ0ESxkBQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# we do the same for test dataset\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "batched_dataset_test = dataset_test.repeat().batch(BATCH_SIZE_TEST)\n",
        "iterator_test = batched_dataset_test.make_one_shot_iterator() \n",
        "(batch_test_images, batch_test_labels) = iterator_test.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_PS2GjTxRZx9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# preprocess input for training and testing\n",
        "def random_flip_left_right(image, flip_index, seed=None):\n",
        "  shape = image.get_shape()\n",
        "  if shape.ndims == 3 or shape.ndims is None:\n",
        "    uniform_random = tf.random_uniform([], 0, 1.0, seed=seed)\n",
        "    mirror_cond = tf.less(uniform_random, .5)\n",
        "    result = tf.cond(\n",
        "        mirror_cond,\n",
        "        lambda: tf.reverse(image, [flip_index]),\n",
        "        lambda: image\n",
        "    )\n",
        "    return fix_image_flip_shape(image, result)\n",
        "  elif shape.ndims == 4:\n",
        "    uniform_random = tf.random_uniform(\n",
        "        [tf.shape(image)[0]], 0, 1.0, seed=seed\n",
        "    )\n",
        "    mirror_cond = tf.less(uniform_random, .5)\n",
        "    return tf.where(\n",
        "        mirror_cond,\n",
        "        image,\n",
        "        tf.map_fn(lambda x: tf.reverse(x, [flip_index]), image, dtype=image.dtype)\n",
        "    )\n",
        "  else:\n",
        "    raise ValueError(\"\\'image\\' must have either 3 or 4 dimensions.\")\n",
        "    \n",
        "def train_image_preprocess(h, w, random_flip=True):\n",
        "  \"\"\"Image processing required for training the model.\"\"\"\n",
        "\n",
        "  def fn(image):\n",
        "    batch_size = image.get_shape().as_list()[0]\n",
        "    # Ensure the data is in range [-1, 1].\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    image = image * 2.0 - 1.0\n",
        "    # Randomly choose a (24, 24, 3) patch to be used for training.\n",
        "    image = tf.random_crop(image, size=(BATCH_SIZE_TRAIN, h, w, 3))\n",
        "    # Randomly flip the image.\n",
        "    image = random_flip_left_right(image, 2)\n",
        "    return image\n",
        "\n",
        "  return fn\n",
        "\n",
        "def test_image_preprocess():\n",
        "  def fn(image):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    image = image * 2.0 - 1.0\n",
        "    return image\n",
        "  return fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gJnSIJ0EqDiu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Teacher model is baseline"
      ]
    },
    {
      "metadata": {
        "id": "2scBoc09ZsO4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class Baseline(snt.AbstractModule):\n",
        "  \n",
        "  def __init__(self, num_classes, name=\"baseline\"):\n",
        "    super(Baseline, self).__init__(name=name)\n",
        "    self._num_classes = num_classes\n",
        "    self._output_channels = [\n",
        "        64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512\n",
        "        ]\n",
        "    self._num_layers = len(self._output_channels)\n",
        "\n",
        "    self._kernel_shapes = [[3, 3]] * self._num_layers  # All kernels are 3x3.\n",
        "    self._strides = [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1]\n",
        "    self._paddings = [snt.SAME] * self._num_layers\n",
        "   \n",
        "  def _build(self, inputs, is_training=None, test_local_stats=False):\n",
        "    net = inputs\n",
        "    # instantiate all the convolutional layers \n",
        "    layers = [snt.Conv2D(name=\"conv_2d_{}\".format(i),\n",
        "                         output_channels=self._output_channels[i],\n",
        "                         kernel_shape=self._kernel_shapes[i],\n",
        "                         stride=self._strides[i],\n",
        "                         padding=self._paddings[i],\n",
        "                         use_bias=True) for i in xrange(self._num_layers)]\n",
        "    # connect them to the graph, adding batch norm and non-linearity\n",
        "    for i, layer in enumerate(layers):\n",
        "      net = layer(net)\n",
        "      bn = snt.BatchNorm(name=\"batch_norm_{}\".format(i))\n",
        "      net = bn(net, is_training=is_training, test_local_stats=test_local_stats)\n",
        "      net = tf.nn.relu(net)\n",
        "\n",
        "    net = tf.reduce_mean(net, reduction_indices=[1, 2], keepdims=False,\n",
        "                         name=\"avg_pool\")\n",
        "\n",
        "    logits = snt.Linear(self._num_classes)(net)\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CZm91aoqqIV7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Student model is Mobilenet"
      ]
    },
    {
      "metadata": {
        "id": "vR3pnr5NVDwj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class Mobilenet(snt.AbstractModule):\n",
        "  \n",
        "  def __init__(self, num_classes, name=\"mobilenet\"):\n",
        "    super(Mobilenet, self).__init__(name=name)\n",
        "    self._num_classes = num_classes\n",
        "    self._channel_multipliers = [\n",
        "        0, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1\n",
        "    ]\n",
        "    self._output_channels = [\n",
        "        64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512\n",
        "    ]\n",
        "    self._num_layers = len(self._output_channels)\n",
        "\n",
        "    self._kernel_shapes = [[3, 3]] * self._num_layers  # All kernels are 3x3.\n",
        "    self._strides = [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1]\n",
        "    self._paddings = [snt.SAME] * self._num_layers\n",
        "   \n",
        "  def _build(self, inputs, is_training=None, test_local_stats=False):\n",
        "    net = inputs\n",
        "    # instantiate all the convolutional layers\n",
        "    first_conv = snt.Conv2D(name=\"conv_2d_0\",\n",
        "                            output_channels=self._output_channels[0],\n",
        "                            kernel_shape=self._kernel_shapes[0],\n",
        "                            stride=self._strides[0],\n",
        "                            padding=self._paddings[0],\n",
        "                            use_bias=True)\n",
        "    \n",
        "    # instantiate depthwise conv layers\n",
        "    conv_layers_dw = [snt.DepthwiseConv2D(name=\"conv_dw_2d_{}\".format(i),\n",
        "                                          channel_multiplier=self._channel_multipliers[i],\n",
        "                                          kernel_shape=self._kernel_shapes[i],\n",
        "                                          stride=self._strides[i],\n",
        "                                          padding=self._paddings[i],\n",
        "                                          use_bias=True)\n",
        "                      for i in xrange(1, self._num_layers)]\n",
        "    \n",
        "    # instantiate 1x1 conv layers\n",
        "    conv_layers_1x1 = [snt.Conv2D(name=\"conv_1x1_2d_{}\".format(i),\n",
        "                                  output_channels=self._output_channels[i],\n",
        "                                  kernel_shape=(1, 1),\n",
        "                                  stride=self._strides[i],\n",
        "                                  padding=self._paddings[i],\n",
        "                                  use_bias=True)\n",
        "                       for i in xrange(1, self._num_layers)]\n",
        "    # connect first layer to the graph, adding batch norm and non-linearity\n",
        "    net = first_conv(net)\n",
        "    bn = snt.BatchNorm(name=\"batch_norm_0\")\n",
        "    net = bn(net, is_training=is_training, test_local_stats=test_local_stats)\n",
        "    net = tf.nn.relu(net)\n",
        "    \n",
        "    # connect the rest of the layers\n",
        "    for i, (layer_dw, layer_1x1) in enumerate(zip(conv_layers_dw, conv_layers_1x1)):\n",
        "      net = layer_dw(net)\n",
        "      bn = snt.BatchNorm(name=\"batch_norm_{}_0\".format(i))\n",
        "      net = bn(net, is_training=is_training, test_local_stats=test_local_stats)\n",
        "      net = tf.nn.relu(net)\n",
        "      net = layer_1x1(net)\n",
        "      bn = snt.BatchNorm(name=\"batch_norm_{}_1\".format(i))\n",
        "      net = bn(net, is_training=is_training, test_local_stats=test_local_stats)\n",
        "      net = tf.nn.relu(net)      \n",
        "\n",
        "    net = tf.reduce_mean(net, reduction_indices=[1, 2], keepdims=False,\n",
        "                         name=\"avg_pool\")\n",
        "\n",
        "    logits = snt.Linear(self._num_classes)(net)\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TZzlpO0oJFZy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# First define the preprocessing ops for the train/test data\n",
        "crop_height = 24 #@param\n",
        "cropt_width = 24 #@param\n",
        "preprocess_fn_train = train_image_preprocess(crop_height, cropt_width)\n",
        "preprocess_fn_test = test_image_preprocess()\n",
        "\n",
        "num_classes = 10 #@param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "698eQkBaVtNg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# for evaluation, we look at top_k_accuracy since it's easier to interpret; normally k=1 or k=5\n",
        "def top_k_accuracy(k, labels, logits):\n",
        "  in_top_k = tf.nn.in_top_k(predictions=tf.squeeze(logits), targets=tf.squeeze(tf.cast(labels, tf.int32)), k=k)\n",
        "  return tf.reduce_mean(tf.cast(in_top_k, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6BoOamgZcFyA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define number of training iterations and reporting intervals\n",
        "TRAIN_ITERS = 90e3 #@param\n",
        "REPORT_TRAIN_EVERY = 100 #@param\n",
        "PLOT_EVERY = 500 #@param\n",
        "REPORT_TEST_EVERY = 1000 #@param\n",
        "TEST_ITERS = 10 #@param\n",
        "lr_init = 0.01 #@param\n",
        "display_inputs = False #@param\n",
        "\n",
        "class_mapping = [u'airplane', u'automobile', u'bird', u'cat', u'deer', u'dog', u'frog', u'horse', u'ship', u'truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xI0ftMtqQjG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Instantiate teacher and load pre-trained weights\n"
      ]
    },
    {
      "metadata": {
        "id": "V9eSqIp5WAKF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(\"teacher\"):\n",
        "  teacher_model = Baseline(num_classes)\n",
        "predictions_teacher = teacher_model(preprocess_fn_train(batch_train_images), is_training=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CtfBZ1_OO3L6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We do not want to alter the teacher weights"
      ]
    },
    {
      "metadata": {
        "id": "S0hD3ZL2O04r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "predictions_teacher = tf.stop_gradient(predictions_teacher)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jtLgURi-O1gA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "var_list = snt.get_variables_in_scope(\"teacher\", collection=tf.GraphKeys.GLOBAL_VARIABLES)  \n",
        "\n",
        "var_map = {}\n",
        "for i in range(0, len(var_list)):\n",
        "  name = var_list[i].name[len(\"teacher/\"):-2]\n",
        "  var_map[name] = var_list[i]\n",
        "\n",
        "saver = tf.train.Saver(var_map, reshape=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UhXzKr-TqlPx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Instantiate student"
      ]
    },
    {
      "metadata": {
        "id": "g3S76cQUqksA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(\"student\"):\n",
        "  student_model = Mobilenet(num_classes=num_classes)\n",
        "# get predictions from the model\n",
        "predictions_student = student_model(preprocess_fn_train(batch_train_images), is_training=True)\n",
        "test_predictions_student = student_model(preprocess_fn_test(batch_test_images), is_training=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TnQvXQDEqqwy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### For distillation, we use softmax with higher temperature. Normally T = 1; for distillation we use T>1.\n",
        "\n",
        "\\begin{equation}\n",
        "q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}\n",
        "\\end{equation}"
      ]
    },
    {
      "metadata": {
        "id": "jzSh3XIDdNMC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# vizualise how the softmax temperature influences the output of the teacher\n",
        "softmax_temp_distill = 5.0   # \n",
        "softmax_temp_normal = 1.0 # \n",
        "logits_high_temp = tf.nn.softmax(tf.div(predictions_teacher, softmax_temp_distill)) \n",
        "logits_low_temp = tf.nn.softmax(tf.div(predictions_teacher, softmax_temp_normal))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TjgjChm_rAm2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set up the training for Mobilenet, adding the distillation loss weighted by the square of temperature\n",
        "- the gradient varies with the inverse of square of temperature"
      ]
    },
    {
      "metadata": {
        "id": "vvnDmLsUc6JU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lambda_ = softmax_temp_distill * softmax_temp_distill"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PzO_NMBKQL4Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define the classification loss**"
      ]
    },
    {
      "metadata": {
        "id": "xc0TDWgUP-SO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "###################\n",
        "#                 # \n",
        "# YOUR CODE       #\n",
        "# train_loss = ...# \n",
        "#                 #\n",
        "###################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FRhpBqgOQPXa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define the distillation loss**\n",
        "\n",
        "You may do this either with\n",
        "\n",
        "* `tf.distributions.kl_divergence` between distributions\n",
        "* `softmax_cross_entropy_with_logits`. Remember that the labels are expected to sum to 1, while the output of the teacher network is logits."
      ]
    },
    {
      "metadata": {
        "id": "ivYOPAmkQOBy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "########################\n",
        "#                      # \n",
        "# YOUR CODE            #\n",
        "# distill_kl_loss = ...# \n",
        "#                      #\n",
        "########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nsfBoN1iQ8D3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define the joint training loss**"
      ]
    },
    {
      "metadata": {
        "id": "amN8bJDcQ6UQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "###################\n",
        "#                 # \n",
        "# YOUR CODE       #\n",
        "# train_loss = ...# \n",
        "#                 #\n",
        "###################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iMgsw2OASSpI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create the training ops\n",
        "\n",
        "Make sure Batch Norm moving averages get updated - run UPDATE_OPS."
      ]
    },
    {
      "metadata": {
        "id": "bg5vcWv1S6Ne",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_optimizer(step):\n",
        "  \"\"\"Get the optimizer used for training.\"\"\"\n",
        "  lr_schedule = (40e3, 60e3, 80e3)\n",
        "  lr_schedule = tf.to_int64(lr_schedule)\n",
        "  lr_factor = 0.1\n",
        "  \n",
        "  lr_init = 0.1\n",
        "  num_epochs = tf.reduce_sum(tf.to_float(step >= lr_schedule))\n",
        "  lr = lr_init * lr_factor**num_epochs\n",
        "\n",
        "  return tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FA04yKaoS-qt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a global step that is incremented during training; useful for e.g. learning rate annealing\n",
        "global_step = tf.train.get_or_create_global_step()\n",
        "\n",
        "# instantiate the optimizer\n",
        "optimizer = get_optimizer(global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gyuKGA1ZSQvC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Get training and test ops\n",
        "training_op = optimizer.minimize(train_loss, global_step)\n",
        "update_ops = tf.group(*tf.get_collection(tf.GraphKeys.UPDATE_OPS))\n",
        "training_op = tf.group(training_op, update_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BLzmNbeLSdgf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Teacher and student accuracy"
      ]
    },
    {
      "metadata": {
        "id": "JbHwP67QSaGh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_acc = top_k_accuracy(1, batch_test_labels, test_predictions_student)\n",
        "acc_teacher = top_k_accuracy(1, batch_train_labels, predictions_teacher) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M6ajGgfzcdh3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the session and initialize variables\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8DKMYb3rIg3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load pre-trained weights for teacher, and check accuracy to make sure the import was successful"
      ]
    },
    {
      "metadata": {
        "id": "LUUJ84-QbyOA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "outputId": "e1087314-f331-4b18-b2e3-5bec60f8268f",
        "executionInfo": {
          "status": "error",
          "timestamp": 1531832217288,
          "user_tz": -60,
          "elapsed": 10698,
          "user": {
            "displayName": "Mihaela Rosca",
            "photoUrl": "//lh5.googleusercontent.com/-q8OFNZCyEkk/AAAAAAAAAAI/AAAAAAAABJg/Qg8HHX2XAI0/s50-c-k-no/photo.jpg",
            "userId": "107992561331291226743"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "saver.restore(sess, \"baseline.ckpt\")\n",
        " \n",
        "test_batch_size = 100\n",
        "num_batches = 100  # 100 batches * 100 samples per batch = 10000\n",
        "\n",
        "avg_accuracy = 0.\n",
        "\n",
        "###################\n",
        "#                 # \n",
        "# YOUR CODE       #\n",
        "#                 #\n",
        "###################\n",
        "\n",
        "# Check if import was done correctly by running eval on cifar train set\n",
        "# expected_accuracy ~ 0.94\n",
        "print (\"Teacher accuracy {:.3f}\".format(avg_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from baseline.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-786808dd87e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"baseline.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m  \u001b[0;31m# 100 batches * 100 samples per batch = 10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mavg_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1750\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1752\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1753\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m       \u001b[0mexception_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[Node: save/RestoreV2/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_221_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sIK7-OSdSkVY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize the impact of temperature on the logits"
      ]
    },
    {
      "metadata": {
        "id": "6GHU1c6bs6ir",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "logits_ht, logits_lt, gt = sess.run([logits_high_temp, logits_low_temp, tf.one_hot(batch_train_labels, num_classes)])\n",
        "# pick one sample and plot\n",
        "idx = 33\n",
        "plt.plot(logits_ht[idx], c='r', label='High Temp')\n",
        "plt.plot(logits_lt[idx], c='g', label='Low Temp')\n",
        "plt.plot(gt[idx,0], 'b--', label='GT')\n",
        "plt.xlim([0,9])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pM9cnYRATPdw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Write a function that takes a list of losses and plots them.\n",
        "def plot_losses(loss_list, steps):\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(pl.gcf())\n",
        "  pl.plot(steps, loss_list, c='b')\n",
        "  time.sleep(1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QHE75BhpSoVk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ]
    },
    {
      "metadata": {
        "id": "C2877dV3Sxxr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_iter = 0\n",
        "losses = []\n",
        "steps = []\n",
        "for train_iter in range(int(TRAIN_ITERS)):\n",
        "  _, train_loss_np = sess.run([training_op, train_loss])\n",
        "  \n",
        "  if (train_iter % REPORT_TRAIN_EVERY) == 0:\n",
        "    losses.append(train_loss_np)\n",
        "    steps.append(train_iter)\n",
        "  if (train_iter % PLOT_EVERY) == 0:\n",
        "    plot_losses(losses, steps)    \n",
        "    \n",
        "  if (train_iter % REPORT_TEST_EVERY) == 0:\n",
        "    avg_acc = 0.0\n",
        "    for test_iter in range(TEST_ITERS):\n",
        "      acc = sess.run(test_acc)\n",
        "      avg_acc += acc\n",
        "      \n",
        "    avg_acc /= (TEST_ITERS)\n",
        "    print ('Test acc at iter {0:5d} out of {1:5d} is {2:.2f}%'.format(int(train_iter), int(TRAIN_ITERS), avg_acc*100.0))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}